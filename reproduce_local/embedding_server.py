#!/usr/bin/env python3
"""
Qwen Embedding HTTPæœåŠ¡å™¨
æ”¯æŒOpenAIå…¼å®¹çš„APIæ ¼å¼
"""

import os
import sys
import argparse
import json
import time
from flask import Flask, request, jsonify
import torch
import numpy as np
from transformers import AutoTokenizer, AutoModel
from typing import List

class QwenEmbeddingServer:
    def __init__(self, model_path: str, device: str = None):
        self.model_path = model_path
        self.device = device if device else ("cuda" if torch.cuda.is_available() else "cpu")
        
        print(f"ğŸ¤– åŠ è½½Qwen Embeddingæ¨¡å‹: {model_path}")
        print(f"ğŸ“± è®¾å¤‡: {self.device}")
        
        # åŠ è½½æ¨¡å‹
        self.tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
        self.model = AutoModel.from_pretrained(model_path, trust_remote_code=True)
        self.model.eval()
        self.model = self.model.to(self.device)
        
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ!")
        
    def encode_texts(self, texts: List[str]) -> np.ndarray:
        """ç¼–ç æ–‡æœ¬ä¸ºå‘é‡"""
        try:
            # Tokenize
            inputs = self.tokenizer(
                texts,
                padding=True,
                truncation=True,
                return_tensors="pt",
                max_length=512
            )
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # ç”Ÿæˆembeddings
            with torch.no_grad():
                outputs = self.model(**inputs)
                embeddings = outputs.last_hidden_state.mean(dim=1)
                embeddings = embeddings.cpu().numpy()
            
            return embeddings
            
        except Exception as e:
            print(f"âŒ Embeddingç”Ÿæˆå¤±è´¥: {e}")
            raise e

def create_app(embedding_server: QwenEmbeddingServer):
    """åˆ›å»ºFlaskåº”ç”¨"""
    app = Flask(__name__)
    
    @app.route('/v1/embeddings', methods=['POST'])
    def get_embeddings():
        """OpenAIå…¼å®¹çš„embeddingsæ¥å£"""
        try:
            data = request.get_json()
            
            # è§£æè¾“å…¥
            input_texts = data.get('input', [])
            if isinstance(input_texts, str):
                input_texts = [input_texts]
            
            model_name = data.get('model', 'qwen-embedding')
            
            # ç”Ÿæˆembeddings
            start_time = time.time()
            embeddings = embedding_server.encode_texts(input_texts)
            end_time = time.time()
            
            # æ„é€ å“åº”
            response = {
                "object": "list",
                "data": [],
                "model": model_name,
                "usage": {
                    "prompt_tokens": sum(len(text.split()) for text in input_texts),
                    "total_tokens": sum(len(text.split()) for text in input_texts)
                }
            }
            
            for i, embedding in enumerate(embeddings):
                response["data"].append({
                    "object": "embedding",
                    "index": i,
                    "embedding": embedding.tolist()
                })
            
            print(f"âœ… å¤„ç† {len(input_texts)} ä¸ªæ–‡æœ¬, ç”¨æ—¶: {end_time-start_time:.3f}s")
            return jsonify(response)
            
        except Exception as e:
            print(f"âŒ è¯·æ±‚å¤„ç†å¤±è´¥: {e}")
            return jsonify({"error": str(e)}), 500
    
    @app.route('/v1/models', methods=['GET'])
    def list_models():
        """åˆ—å‡ºå¯ç”¨æ¨¡å‹"""
        return jsonify({
            "object": "list",
            "data": [{
                "id": "qwen-embedding",
                "object": "model",
                "created": int(time.time()),
                "owned_by": "local"
            }]
        })
    
    @app.route('/health', methods=['GET'])
    def health_check():
        """å¥åº·æ£€æŸ¥"""
        return jsonify({"status": "healthy"})
    
    return app

def main():
    parser = argparse.ArgumentParser(description="Qwen Embedding HTTPæœåŠ¡å™¨")
    parser.add_argument("--model-path", required=True, help="æ¨¡å‹è·¯å¾„")
    parser.add_argument("--host", default="0.0.0.0", help="æœåŠ¡åœ°å€")
    parser.add_argument("--port", type=int, required=True, help="ç«¯å£å·")
    parser.add_argument("--device", default=None, help="è®¾å¤‡ (cuda/cpu)")
    
    args = parser.parse_args()
    
    # åˆ›å»ºEmbeddingæœåŠ¡å™¨
    embedding_server = QwenEmbeddingServer(
        model_path=args.model_path,
        device=args.device
    )
    
    # åˆ›å»ºFlaskåº”ç”¨
    app = create_app(embedding_server)
    
    print(f"ğŸš€ å¯åŠ¨Qwen EmbeddingæœåŠ¡:")
    print(f"  åœ°å€: http://{args.host}:{args.port}")
    print(f"  æ¨¡å‹: {args.model_path}")
    print(f"  è®¾å¤‡: {embedding_server.device}")
    
    # å¯åŠ¨æœåŠ¡
    app.run(host=args.host, port=args.port, threaded=True)

if __name__ == "__main__":
    main()
