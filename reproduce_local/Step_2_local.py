import json
import os
from transformers import AutoTokenizer
from local_models import oss_llm_complete

# åŠ è½½OSSæ¨¡å‹çš„tokenizer
OSS_MODEL_PATH = "/mnt/jfs/xubenfeng/model/gpt-oss-120b"
oss_tokenizer = AutoTokenizer.from_pretrained(OSS_MODEL_PATH)

def get_summary(context, tot_tokens=2000):
    """æå–æ–‡æ¡£æ‘˜è¦ï¼ˆä½¿ç”¨OSS tokenizerï¼Œå®Œå…¨æŒ‰ç…§åŸå§‹é€»è¾‘ï¼‰"""
    # å®Œå…¨æŒ‰ç…§åŸå§‹Step_2.pyçš„é€»è¾‘
    tokens = oss_tokenizer.tokenize(context)
    half_tokens = tot_tokens // 2

    start_tokens = tokens[1000 : 1000 + half_tokens]
    end_tokens = tokens[-(1000 + half_tokens) : -1000] if len(tokens) > 1000 else tokens[-(1000 + half_tokens):]

    summary_tokens = start_tokens + end_tokens
    summary = oss_tokenizer.convert_tokens_to_string(summary_tokens)

    return summary

def generate_questions_for_class(cls):
    """ä¸ºæŒ‡å®šç±»åˆ«ç”Ÿæˆé—®é¢˜"""
    unique_contexts_file = f"../exp_results/data/unique_contexts/{cls}_unique_contexts.json"
    
    if not os.path.exists(unique_contexts_file):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {unique_contexts_file}")
        return
    
    print(f"æ­£åœ¨å¤„ç†ç±»åˆ«: {cls}")
    print(f"è¯»å–æ–‡ä»¶: {unique_contexts_file}")
    
    with open(unique_contexts_file, mode="r") as f:
        unique_contexts = json.load(f)

    print(f"æ–‡æ¡£æ•°é‡: {len(unique_contexts)}")
    
    # ç”Ÿæˆæ‘˜è¦
    print("æ­£åœ¨ç”Ÿæˆæ–‡æ¡£æ‘˜è¦...")
    summaries = [get_summary(context) for context in unique_contexts]
    total_description = "\n\n".join(summaries)

    prompt = f"""
Given the following description of a dataset:

<description>
{total_description}
</description>

<instructions>
Please identify 5 potential users who would engage with this dataset. For each user, list 5 tasks they would perform with this dataset. Then, for each (user, task) combination, generate 5 questions that require a high-level understanding of the entire dataset.
</instructions>

Output the results in the following structure (with exact format):
```
- User 1: [user description]
    - Task 1: [task description]
        - Question 1:
        - Question 2:
        - Question 3:
        - Question 4:
        - Question 5:
    - Task 2: [task description]
        ...
    - Task 5: [task description]
- User 2: [user description]
    ...
- User 5: [user description]
    ...
```
"""

    print("æ­£åœ¨è°ƒç”¨OSS APIç”Ÿæˆé—®é¢˜...")
    result = oss_llm_complete(prompt=prompt, max_tokens=4096, temperature=0.7)

    # åˆ›å»ºè¾“å‡ºç›®å½•
    questions_dir = "../exp_results/data/questions"
    os.makedirs(questions_dir, exist_ok=True)
    
    # ä¿å­˜ç»“æœ
    file_path = f"{questions_dir}/{cls}_questions.txt"
    with open(file_path, "w", encoding="utf-8") as file:
        file.write(result)

    print(f"âœ… {cls}_questions å·²ä¿å­˜åˆ° {file_path}")
    return result

def main():
    """ä¸»å‡½æ•°"""
    # ä»ç¯å¢ƒå˜é‡è¯»å–ç±»åˆ«ï¼Œé»˜è®¤ä¸ºagriculture
    cls = os.getenv("CLASS", "agriculture")
    classes_to_process = [cls]
    print(f"ğŸ“Š å¤„ç†æ•°æ®é›†ç±»åˆ«: {cls}")
    
    for cls in classes_to_process:
        try:
            generate_questions_for_class(cls)
            print(f"âœ… {cls} å¤„ç†å®Œæˆ\n")
        except Exception as e:
            print(f"âŒ å¤„ç† {cls} æ—¶å‡ºé”™: {e}\n")

if __name__ == "__main__":
    main()
