import re
import json
import os
import asyncio
from lightrag import LightRAG, QueryParam
from lightrag.utils import EmbeddingFunc
from lightrag.kg.shared_storage import initialize_pipeline_status
from local_models import (
    lightrag_llm_func_async, 
    lightrag_embedding_func_async, 
    get_embedding_dim,
    init_qwen_embedding
)

def extract_queries(file_path):
    """ä»ç”Ÿæˆçš„é—®é¢˜æ–‡ä»¶ä¸­æå–æŸ¥è¯¢"""
    with open(file_path, "r", encoding="utf-8") as f:
        data = f.read()

    # å®Œå…¨æŒ‰ç…§åŸå§‹Step_3.pyçš„é€»è¾‘
    data = data.replace("**", "")
    queries = re.findall(r"- Question \d+: (.+)", data)
    
    return queries

async def process_query(query_text, rag_instance, query_param):
    """å¤„ç†å•ä¸ªæŸ¥è¯¢"""
    try:
        result = await rag_instance.aquery(query_text, param=query_param)
        return {"query": query_text, "result": result}, None
    except Exception as e:
        return None, {"query": query_text, "error": str(e)}

async def run_queries_and_save_to_json(
    queries, rag_instance, query_param, output_file, error_file
):
    """è¿è¡ŒæŸ¥è¯¢å¹¶ä¿å­˜ç»“æœ"""
    with (
        open(output_file, "w", encoding="utf-8") as result_file,
        open(error_file, "w", encoding="utf-8") as err_file,
    ):
        result_file.write("[\n")
        first_entry = True

        for i, query_text in enumerate(queries):
            print(f"å¤„ç†æŸ¥è¯¢ {i+1}/{len(queries)}: {query_text[:100]}...")
            
            result, error = await process_query(query_text, rag_instance, query_param)

            if result:
                if not first_entry:
                    result_file.write(",\n")
                json.dump(result, result_file, ensure_ascii=False, indent=4)
                first_entry = False
                print(f"âœ… æŸ¥è¯¢ {i+1} å®Œæˆ")
            elif error:
                json.dump(error, err_file, ensure_ascii=False, indent=4)
                err_file.write("\n")
                print(f"âŒ æŸ¥è¯¢ {i+1} å¤±è´¥: {error['error']}")

        result_file.write("\n]")

async def initialize_rag(cls):
    """åˆå§‹åŒ–RAGå®ä¾‹"""
    working_dir = f"../{cls}"
    
    if not os.path.exists(working_dir):
        print(f"âŒ å·¥ä½œç›®å½•ä¸å­˜åœ¨: {working_dir}")
        print("è¯·å…ˆè¿è¡Œ Step_1_local.py æ¥æ„å»ºçŸ¥è¯†å›¾è°±")
        return None
    
    print("æ­£åœ¨åˆå§‹åŒ–æœ¬åœ°æ¨¡å‹...")
    
    # é¢„å…ˆåˆå§‹åŒ–Qwen Embeddingæ¨¡å‹
    init_qwen_embedding()
    embedding_dim = get_embedding_dim()
    print(f"âœ… Embeddingç»´åº¦: {embedding_dim}")
    
    # åˆ›å»ºLightRAGå®ä¾‹
    rag = LightRAG(
        working_dir=working_dir,
        llm_model_func=lightrag_llm_func_async,  # ä½¿ç”¨OSS LLM
        embedding_func=EmbeddingFunc(
            embedding_dim=embedding_dim,
            func=lightrag_embedding_func_async  # ä½¿ç”¨Qwen Embedding
        ),
    )

    await rag.initialize_storages()
    await initialize_pipeline_status()
    
    print("âœ… LightRAGåˆå§‹åŒ–å®Œæˆ!")
    return rag

async def process_class_queries(cls, query_modes=["naive", "local", "global", "hybrid"]):
    """å¤„ç†æŒ‡å®šç±»åˆ«çš„æŸ¥è¯¢"""
    print(f"\nå¼€å§‹å¤„ç†ç±»åˆ«: {cls}")
    
    # æ£€æŸ¥é—®é¢˜æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    questions_file = f"../exp_results/data/questions/{cls}_questions.txt"
    if not os.path.exists(questions_file):
        print(f"âŒ é—®é¢˜æ–‡ä»¶ä¸å­˜åœ¨: {questions_file}")
        print("è¯·å…ˆè¿è¡Œ Step_2_local.py æ¥ç”Ÿæˆé—®é¢˜")
        return
    
    # æå–æŸ¥è¯¢
    queries = extract_queries(questions_file)
    print(f"æå–åˆ° {len(queries)} ä¸ªæŸ¥è¯¢")
    
    if len(queries) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æŸ¥è¯¢")
        return
    
    # åˆå§‹åŒ–RAGå®ä¾‹
    rag = await initialize_rag(cls)
    if rag is None:
        return
    
    # åˆ›å»ºç»“æœç›®å½•
    results_dir = "../exp_results/data/results"
    os.makedirs(results_dir, exist_ok=True)
    
    # å¯¹æ¯ç§æŸ¥è¯¢æ¨¡å¼è¿è¡ŒæŸ¥è¯¢
    for mode in query_modes:
        print(f"\næ­£åœ¨è¿è¡Œ {mode} æ¨¡å¼æŸ¥è¯¢...")
        
        query_param = QueryParam(mode=mode, enable_rerank=False)
        output_file = f"{results_dir}/{cls}_{mode}_results.json"
        error_file = f"{results_dir}/{cls}_{mode}_errors.json"
        
        await run_queries_and_save_to_json(
            queries, rag, query_param, output_file, error_file
        )
        
        print(f"âœ… {mode} æ¨¡å¼æŸ¥è¯¢å®Œæˆï¼Œç»“æœä¿å­˜åˆ°: {output_file}")

async def main():
    """ä¸»å‡½æ•°"""
    # ä»ç¯å¢ƒå˜é‡è¯»å–ç±»åˆ«ï¼Œé»˜è®¤ä¸ºagriculture
    cls = os.getenv("CLASS", "agriculture")
    classes_to_process = [cls]
    query_modes = ["naive", "local", "global", "hybrid"]  # å¯ä»¥é€‰æ‹©æ€§ç§»é™¤æŸäº›æ¨¡å¼
    
    print(f"ğŸ“Š å¤„ç†æ•°æ®é›†ç±»åˆ«: {cls}")
    print(f"ğŸ” æŸ¥è¯¢æ¨¡å¼: {', '.join(query_modes)}")
    
    for cls in classes_to_process:
        try:
            await process_class_queries(cls, query_modes)
            print(f"\nâœ… {cls} æ‰€æœ‰æŸ¥è¯¢æ¨¡å¼å¤„ç†å®Œæˆ")
        except Exception as e:
            print(f"\nâŒ å¤„ç† {cls} æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())
