#!/bin/bash

# å¤šGPU OSSæœåŠ¡å¯åŠ¨è„šæœ¬
# ä¸€æ¬¡æ€§å¯åŠ¨8ä¸ªæœåŠ¡ï¼šç«¯å£30061~30068ï¼Œæ¯ä¸ªæœåŠ¡ä½¿ç”¨1å¼ GPUå¡

# å¦‚æœä½ æ˜¯ç”¨é•œåƒä»£ç†æ‹‰çš„ï¼ŒæŠŠ IMG æ¢æˆä½ æœ¬åœ°çš„é‚£ä¸ªåå­—å³å¯
# IMG=docker.m.daocloud.io/lmsysorg/sglang:v0.5.0rc2-cu126

IMG=hub-cn-shanghai-2.kce.ksyun.com/ystrain/ystrain:sglang.v0.5.0rc2-cu126.oss
CONTAINER_NAME=inference_oss_multi

# é…ç½®å‚æ•°
START_PORT=30061
END_PORT=30068
MODEL_PATH="/mnt/raid/model/gpt-oss-120b"
LOG_DIR="/mnt/jfs/xubenfeng/model/logs"
TIKTOKEN_CACHE="/mnt/jfs/xubenfeng/model/openai_harmony_vocab"

# åˆ›å»ºæ—¥å¿—ç›®å½•
echo "æ­£åœ¨åˆ›å»ºæ—¥å¿—ç›®å½•: $LOG_DIR"
mkdir -p $LOG_DIR

echo "æ­£åœ¨æ£€æŸ¥æ˜¯å¦å­˜åœ¨åŒåå®¹å™¨..."
# åœæ­¢å¹¶åˆ é™¤å·²å­˜åœ¨çš„åŒåå®¹å™¨
if docker ps -a --format 'table {{.Names}}' | grep -q "^${CONTAINER_NAME}$"; then
    echo "å‘ç°å·²å­˜åœ¨å®¹å™¨ ${CONTAINER_NAME}ï¼Œæ­£åœ¨åœæ­¢å¹¶åˆ é™¤..."
    docker stop ${CONTAINER_NAME} > /dev/null 2>&1
    docker rm ${CONTAINER_NAME} > /dev/null 2>&1
fi

echo "ğŸš€ å°†å¯åŠ¨ $((END_PORT - START_PORT + 1)) ä¸ªOSSæœåŠ¡"
echo "ğŸ“Š ç«¯å£èŒƒå›´: $START_PORT - $END_PORT"
echo "ğŸ¯ æ¯ä¸ªæœåŠ¡ä½¿ç”¨1å¼ GPUå¡"
echo "ğŸ“ æ—¥å¿—ç›®å½•: $LOG_DIR"

echo "æ­£åœ¨å¯åŠ¨å®¹å™¨ ${CONTAINER_NAME}..."
# 1) èµ·ä¸€ä¸ªå¸¸é©»çš„å®¹å™¨ï¼ˆç”¨ sleep ä¿æ´»ï¼‰ï¼Œåå­—ä¸è¦ç”¨æ–œæ 
docker run -d --gpus all --rm -ti \
  --name ${CONTAINER_NAME} \
  --privileged --cap-add=IPC_LOCK \
  --ulimit memlock=-1 --ulimit stack=67108864 \
  --net=host --ipc=host \
  -v /mnt:/mnt \
  $IMG bash -lc "sleep infinity"

# æ£€æŸ¥å®¹å™¨æ˜¯å¦å¯åŠ¨æˆåŠŸ
if [ $? -ne 0 ]; then
    echo "é”™è¯¯ï¼šå®¹å™¨å¯åŠ¨å¤±è´¥"
    exit 1
fi

echo "å®¹å™¨å¯åŠ¨æˆåŠŸï¼Œç­‰å¾…3ç§’..."
sleep 3

echo "æ­£åœ¨å®¹å™¨å†…å¯åŠ¨å¤šä¸ª sglang æœåŠ¡å™¨..."

# å¾ªç¯å¯åŠ¨å¤šä¸ªæœåŠ¡
for port in $(seq $START_PORT $END_PORT); do
    gpu_id=$((port - START_PORT))  # GPU ID: 0,1,2,3,4,5,6,7
    log_file="$LOG_DIR/server_port_${port}_gpu_${gpu_id}.log"
    
    echo "ğŸ”„ å¯åŠ¨æœåŠ¡ GPU:$gpu_id Port:$port"
    
    # åœ¨å®¹å™¨å†…å¯åŠ¨å•ä¸ªæœåŠ¡
    docker exec ${CONTAINER_NAME} bash -c "
    export TIKTOKEN_RS_CACHE_DIR=$TIKTOKEN_CACHE
    export CUDA_VISIBLE_DEVICES=$gpu_id
    echo 'æ­£åœ¨å¯åŠ¨ sglang æœåŠ¡å™¨ - GPU:$gpu_id Port:$port'
    nohup python3 -m sglang.launch_server \
      --model $MODEL_PATH \
      --tp 1 \
      --host 0.0.0.0 --port $port \
      --mem-fraction-static 0.9 > $log_file 2>&1 &
    echo 'GPU:$gpu_id Port:$port æœåŠ¡å·²åœ¨åå°å¯åŠ¨'
    echo 'æ—¥å¿—æ–‡ä»¶: $log_file'
    "
    
    # æ¯ä¸ªæœåŠ¡å¯åŠ¨é—´éš”2ç§’ï¼Œé¿å…åŒæ—¶å¯åŠ¨é€ æˆèµ„æºç«äº‰
    sleep 2
done

# ç­‰å¾…æ‰€æœ‰æœåŠ¡å®Œå…¨å¯åŠ¨
echo "â° ç­‰å¾…60ç§’è®©æ‰€æœ‰æœåŠ¡å®Œå…¨å¯åŠ¨..."
sleep 60

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
echo "ğŸ” æ£€æŸ¥æœåŠ¡çŠ¶æ€..."
running_services=0
for port in $(seq $START_PORT $END_PORT); do
    # ç®€å•æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«ç›‘å¬
    if docker exec ${CONTAINER_NAME} bash -c "netstat -tuln | grep :$port" >/dev/null 2>&1; then
        echo "âœ… Port $port: è¿è¡Œä¸­"
        running_services=$((running_services + 1))
    else
        echo "âŒ Port $port: æœªå¯åŠ¨"
    fi
done

echo ""
echo "ğŸ‰ éƒ¨ç½²å®Œæˆï¼"
echo "===================="
echo "å®¹å™¨åç§°: ${CONTAINER_NAME}"
echo "æœåŠ¡æ•°é‡: $running_services/$((END_PORT - START_PORT + 1))"
echo "ç«¯å£èŒƒå›´: $START_PORT - $END_PORT"
echo "æ—¥å¿—ç›®å½•: $LOG_DIR"
echo ""
echo "ğŸ“ å¸¸ç”¨å‘½ä»¤:"
echo "æŸ¥çœ‹æ‰€æœ‰æ—¥å¿—: ls -la $LOG_DIR/"
echo "æŸ¥çœ‹ç‰¹å®šæ—¥å¿—: tail -f $LOG_DIR/server_port_30061_gpu_0.log"
echo "è¿›å…¥å®¹å™¨: docker exec -it ${CONTAINER_NAME} bash"
echo "åœæ­¢å®¹å™¨: docker stop ${CONTAINER_NAME}"
echo ""
echo "ğŸŒ æœåŠ¡åœ°å€:"
for port in $(seq $START_PORT $END_PORT); do
    gpu_id=$((port - START_PORT))
    echo "  GPU$gpu_id: http://0.0.0.0:$port"
done
echo ""
echo "ğŸ§ª æµ‹è¯•å‘½ä»¤:"
echo "curl -X POST http://0.0.0.0:30061/v1/chat/completions \\"
echo "  -H \"Content-Type: application/json\" \\"
echo "  -d '{\"model\":\"default\",\"messages\":[{\"role\":\"user\",\"content\":\"Hello\"}]}'"